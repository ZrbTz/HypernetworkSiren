{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"1_MLAI_SIREN_with_PSNR_and_laplacian.ipynb","provenance":[{"file_id":"10eqNZuTfRWX6KiZi5__Qr4oF_KOwDTeW","timestamp":1612130420182},{"file_id":"1DZTfd2WDaAwCKNXbf31AefJyke1kZgSX","timestamp":1611590747115}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"cells":[{"cell_type":"markdown","metadata":{"id":"PS0bD_TuGukM"},"source":["# Siren Exploration\n","\n","This is a colab to explore properties of the Siren MLP, proposed in our work [Implicit Neural Activations with Periodic Activation Functions](https://vsitzmann.github.io/siren).\n","\n","\n","We will first implement a streamlined version of Siren for fast experimentation. This lacks the code to easily do baseline comparisons - please refer to the main code for that - but will greatly simplify the code!\n","\n","**Make sure that you have enabled the GPU under Edit -> Notebook Settings!**\n","\n","We will then reproduce the following results from the paper: \n","* [Fitting an image](#section_1)\n","* [Fitting an audio signal](#section_2)\n","* [Solving Poisson's equation](#section_3)\n","* [Initialization scheme & distribution of activations](#activations)\n","* [Distribution of activations is shift-invariant](#shift_invariance)\n","\n","We will also explore Siren's [behavior outside of the training range](#out_of_range).\n","\n","Let's go! First, some imports, and a function to quickly generate coordinate grids."]},{"cell_type":"code","metadata":{"id":"DIBgEHRSGukM","executionInfo":{"status":"ok","timestamp":1612134802021,"user_tz":-60,"elapsed":1603,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","\n","from PIL import Image\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n","import numpy as np\n","import skimage\n","import matplotlib.pyplot as plt\n","import matplotlib.pyplot as plt\n","from math import log10, sqrt\n","\n","import time\n","\n","def get_mgrid(sidelen, dim=2):  #function to generate the coordinate grid\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n","    sidelen: int\n","    dim: int'''\n","\n","    #torch.linspace(-1, 1, steps=sidelen):\n","    #Creates a one-dimensional tensor of size steps whose values are evenly\n","    #spaced from start (=-1) to end (=1), inclusive.\n","\n","    #dim * [..]\n","    #replicate the content of [] dim times, the result will be a list of dim\n","    #elements (in this case tensors)\n","\n","    #tuple([..])\n","    #transforms the list in input in a tuple\n","\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n","\n","    #torch.meshgrid(*tensors):\n","    #Take N tensors, each of which can be either scalar or 1-dimensional vector,\n","    #and create N N-dimensional grids, where the i-th grid is defined by\n","    #expanding the i-th input over dimensions defined by other inputs.\n","\n","    #torch.stack(...,dim=-1):\n","    #Concatenates a sequence of tensors along a new dimension\n","    #dim = -1 -> calculate the dimensions automatically\n","\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","\n","    #mgrid.reshape(-1, dim):\n","    #Returns a tensor with the same data and number of elements as input,\n","    #but with the specified shape.\n","    #dim = -1 -> calculate the dimensions automatically\n","\n","    #from a list of lists (3 dimensions) to a single list (2 dimensions)\n","\n","    mgrid = mgrid.reshape(-1, dim)\n","    return mgrid\n","\n","def psnr(input, target):\n","    MSE = ((input - target)**2).mean() \n","    PSNR_reconstructed_image = 20*log10(1/sqrt(MSE.item()))\n","    return PSNR_reconstructed_image"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0n9pWotXw4Vz","executionInfo":{"status":"ok","timestamp":1612134803031,"user_tz":-60,"elapsed":2609,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"058417ad-fdcd-4752-a855-4bb498bd9a9d"},"source":["#my_test\n","print([torch.linspace(-1, 1, steps=5)])\n","print(2 * [torch.linspace(-1, 1, steps=5)])\n","tensors = tuple(2 * [torch.linspace(-1, 1, steps=5)])\n","print(tensors)\n","torch.meshgrid(*tensors)\n","mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n","print(mgrid)\n","print(mgrid.reshape(-1, 2))\n","\n","print(get_mgrid(256, 2))\n","print(get_mgrid(256, 2).shape)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000])]\n","[tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]), tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000])]\n","(tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]), tensor([-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]))\n","tensor([[[-1.0000, -1.0000],\n","         [-1.0000, -0.5000],\n","         [-1.0000,  0.0000],\n","         [-1.0000,  0.5000],\n","         [-1.0000,  1.0000]],\n","\n","        [[-0.5000, -1.0000],\n","         [-0.5000, -0.5000],\n","         [-0.5000,  0.0000],\n","         [-0.5000,  0.5000],\n","         [-0.5000,  1.0000]],\n","\n","        [[ 0.0000, -1.0000],\n","         [ 0.0000, -0.5000],\n","         [ 0.0000,  0.0000],\n","         [ 0.0000,  0.5000],\n","         [ 0.0000,  1.0000]],\n","\n","        [[ 0.5000, -1.0000],\n","         [ 0.5000, -0.5000],\n","         [ 0.5000,  0.0000],\n","         [ 0.5000,  0.5000],\n","         [ 0.5000,  1.0000]],\n","\n","        [[ 1.0000, -1.0000],\n","         [ 1.0000, -0.5000],\n","         [ 1.0000,  0.0000],\n","         [ 1.0000,  0.5000],\n","         [ 1.0000,  1.0000]]])\n","tensor([[-1.0000, -1.0000],\n","        [-1.0000, -0.5000],\n","        [-1.0000,  0.0000],\n","        [-1.0000,  0.5000],\n","        [-1.0000,  1.0000],\n","        [-0.5000, -1.0000],\n","        [-0.5000, -0.5000],\n","        [-0.5000,  0.0000],\n","        [-0.5000,  0.5000],\n","        [-0.5000,  1.0000],\n","        [ 0.0000, -1.0000],\n","        [ 0.0000, -0.5000],\n","        [ 0.0000,  0.0000],\n","        [ 0.0000,  0.5000],\n","        [ 0.0000,  1.0000],\n","        [ 0.5000, -1.0000],\n","        [ 0.5000, -0.5000],\n","        [ 0.5000,  0.0000],\n","        [ 0.5000,  0.5000],\n","        [ 0.5000,  1.0000],\n","        [ 1.0000, -1.0000],\n","        [ 1.0000, -0.5000],\n","        [ 1.0000,  0.0000],\n","        [ 1.0000,  0.5000],\n","        [ 1.0000,  1.0000]])\n","tensor([[-1.0000, -1.0000],\n","        [-1.0000, -0.9922],\n","        [-1.0000, -0.9843],\n","        ...,\n","        [ 1.0000,  0.9843],\n","        [ 1.0000,  0.9922],\n","        [ 1.0000,  1.0000]])\n","torch.Size([65536, 2])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YQQccJ2hGukM"},"source":["Now, we code up the sine layer, which will be the basic building block of SIREN. This is a much more concise implementation than the one in the main code, as here, we aren't concerned with the baseline comparisons."]},{"cell_type":"code","metadata":{"id":"KZQbknjiGukM","executionInfo":{"status":"ok","timestamp":1612134803033,"user_tz":-60,"elapsed":2605,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["class SineLayer(nn.Module):\n","    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n","    \n","    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n","    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n","    # hyperparameter.\n","    \n","    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n","    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n","    \n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, omega_0=30):\n","        super().__init__()\n","        self.omega_0 = omega_0\n","        self.is_first = is_first\n","        \n","        self.in_features = in_features\n","        self.linear = nn.Linear(in_features, out_features, bias=bias)\n","        \n","        self.init_weights()\n","    \n","    def init_weights(self):\n","        with torch.no_grad(): #Context-manager that disables gradient calculation\n","            if self.is_first:\n","                #Fills the input Tensor with values drawn from the uniform distribution\n","\n","                #Initialize weights\n","                self.linear.weight.uniform_(-1 / self.in_features, \n","                                             1 / self.in_features)\n","            else:\n","                #Fills the input Tensor with values drawn from the uniform distribution\n","\n","                #Initialize weights\n","                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n","                                             np.sqrt(6 / self.in_features) / self.omega_0)\n","        \n","    def forward(self, input): #forward pass\n","        return torch.sin(self.omega_0 * self.linear(input))\n","    \n","    def forward_with_intermediate(self, input): #forward pass with intermediate\n","        # For visualization of activation distributions\n","        intermediate = self.omega_0 * self.linear(input)\n","        return torch.sin(intermediate), intermediate\n","    \n","    \n","class Siren(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n","                 first_omega_0=30, hidden_omega_0=30.):\n","        super().__init__()\n","        \n","        self.net = []   #net\n","\n","        #append the first sine layer\n","        self.net.append(SineLayer(in_features, hidden_features, \n","                                  is_first=True, omega_0=first_omega_0))\n","\n","        #append all the other sine layers\n","        for i in range(hidden_layers):\n","            self.net.append(SineLayer(hidden_features, hidden_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","\n","        #if the outermost_linear bool is set then add a final linear layer\n","        if outermost_linear:\n","            final_linear = nn.Linear(hidden_features, out_features)\n","            \n","            with torch.no_grad(): #Context-manager that disables gradient calculation\n","                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n","                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n","                \n","            self.net.append(final_linear)\n","        else:\n","            self.net.append(SineLayer(hidden_features, out_features, \n","                                      is_first=False, omega_0=hidden_omega_0))\n","        \n","        #nn.Sequential(*self.net):\n","        #A sequential container. Modules will be added to it in the order they\n","        #are passed in the constructor.\n","\n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):  #forward pass\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords) #apply coords on net\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):  #forward pass with activations\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)  # allows to take derivative w.r.t. input\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):  #for all layers of the net\n","            if isinstance(layer, SineLayer):  #if it is a sine layer\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                #retain_grad():\n","                #Enables .grad attribute for non-leaf Tensors.\n","\n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXobZwxbGukM"},"source":["And finally, differential operators that allow us to leverage autograd to compute gradients, the laplacian, etc."]},{"cell_type":"code","metadata":{"id":"PQz-uxEFGukN","executionInfo":{"status":"ok","timestamp":1612134803033,"user_tz":-60,"elapsed":2603,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["def laplace(y, x):\n","    grad = gradient(y, x)\n","    return divergence(grad, x)\n","\n","\n","def divergence(y, x):\n","    div = 0.\n","    for i in range(y.shape[-1]):\n","        #torch.autograd.grad(...)\n","        #Computes and returns the sum of gradients of outputs w.r.t. the inputs.\n","        div += torch.autograd.grad(y[..., i], x, torch.ones_like(y[..., i]), create_graph=True)[0][..., i:i+1]\n","    return div\n","\n","\n","def gradient(y, x, grad_outputs=None):\n","    if grad_outputs is None:\n","        #torch.ones_like(input)\n","        #Returns a tensor filled with the scalar value 1, with the same size as input.\n","        grad_outputs = torch.ones_like(y)\n","\n","    #torch.autograd.grad(...)\n","    #Computes and returns the sum of gradients of outputs w.r.t. the inputs.\n","    grad = torch.autograd.grad(y, [x], grad_outputs=grad_outputs, create_graph=True)[0]\n","    return grad"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTUGw5s3nIFY","executionInfo":{"status":"ok","timestamp":1612134803034,"user_tz":-60,"elapsed":2601,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["import torch\r\n","from torch import nn\r\n","import torch.nn.functional as F\r\n","from torch.utils.data import DataLoader, Dataset\r\n","import os\r\n","\r\n","from PIL import Image\r\n","from torchvision.transforms import Resize, Compose, ToTensor, Normalize\r\n","import numpy as np\r\n","import skimage\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib.pyplot as plt\r\n","from math import log10, sqrt\r\n","\r\n","import time\r\n","\r\n","def get_mgrid(sidelen, dim=2):  #function to generate the coordinate grid\r\n","    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\r\n","    sidelen: int\r\n","    dim: int'''\r\n","\r\n","    #torch.linspace(-1, 1, steps=sidelen):\r\n","    #Creates a one-dimensional tensor of size steps whose values are evenly\r\n","    #spaced from start (=-1) to end (=1), inclusive.\r\n","\r\n","    #dim * [..]\r\n","    #replicate the content of [] dim times, the result will be a list of dim\r\n","    #elements (in this case tensors)\r\n","\r\n","    #tuple([..])\r\n","    #transforms the list in input in a tuple\r\n","\r\n","    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\r\n","\r\n","    #torch.meshgrid(*tensors):\r\n","    #Take N tensors, each of which can be either scalar or 1-dimensional vector,\r\n","    #and create N N-dimensional grids, where the i-th grid is defined by\r\n","    #expanding the i-th input over dimensions defined by other inputs.\r\n","\r\n","    #torch.stack(...,dim=-1):\r\n","    #Concatenates a sequence of tensors along a new dimension\r\n","    #dim = -1 -> calculate the dimensions automatically\r\n","\r\n","    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\r\n","\r\n","    #mgrid.reshape(-1, dim):\r\n","    #Returns a tensor with the same data and number of elements as input,\r\n","    #but with the specified shape.\r\n","    #dim = -1 -> calculate the dimensions automatically\r\n","\r\n","    #from a list of lists (3 dimensions) to a single list (2 dimensions)\r\n","\r\n","    mgrid = mgrid.reshape(-1, dim)\r\n","    return mgrid"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUwcaVRaGukN","executionInfo":{"status":"ok","timestamp":1612134803034,"user_tz":-60,"elapsed":2599,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["def get_cameraman_tensor(sidelength):\n","    #skimage.data.camera():\n","    #Gray-level “camera” image\n","\n","    img = Image.fromarray(skimage.data.camera())        \n","    transform = Compose([\n","        Resize(sidelength),\n","        ToTensor(),\n","        Normalize(torch.Tensor([0.5]), torch.Tensor([0.5])) #normalize\n","    ])\n","    img = transform(img)  #image tensor of dimension (1, sidelength, sidelength)\n","    return img"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEeqGuWN1xQf","executionInfo":{"status":"ok","timestamp":1612134803034,"user_tz":-60,"elapsed":2597,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"703f0b1c-f19c-44ed-8cee-026778e583cd"},"source":["cameraman = get_cameraman_tensor(256)\n","print(cameraman)\n","print(cameraman.shape)\n","\n","print()\n","print(cameraman.permute(1, 2, 0))\n","print(cameraman.permute(1, 2, 0).shape)\n","\n","print()\n","print(cameraman.permute(1, 2, 0).view(-1, 1))\n","print(cameraman.permute(1, 2, 0).view(-1, 1).shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[[ 0.2314,  0.2392,  0.2314,  ...,  0.1843,  0.1843,  0.1922],\n","         [ 0.2314,  0.2235,  0.2314,  ...,  0.2000,  0.2000,  0.1922],\n","         [ 0.2314,  0.2314,  0.2235,  ...,  0.1922,  0.2000,  0.2000],\n","         ...,\n","         [-0.0431, -0.0118, -0.0667,  ...,  0.0510,  0.0039, -0.0980],\n","         [-0.0431, -0.0039,  0.0431,  ...,  0.0431, -0.0118, -0.1137],\n","         [-0.0353, -0.0118,  0.1137,  ...,  0.0353, -0.0196, -0.1137]]])\n","torch.Size([1, 256, 256])\n","\n","tensor([[[ 0.2314],\n","         [ 0.2392],\n","         [ 0.2314],\n","         ...,\n","         [ 0.1843],\n","         [ 0.1843],\n","         [ 0.1922]],\n","\n","        [[ 0.2314],\n","         [ 0.2235],\n","         [ 0.2314],\n","         ...,\n","         [ 0.2000],\n","         [ 0.2000],\n","         [ 0.1922]],\n","\n","        [[ 0.2314],\n","         [ 0.2314],\n","         [ 0.2235],\n","         ...,\n","         [ 0.1922],\n","         [ 0.2000],\n","         [ 0.2000]],\n","\n","        ...,\n","\n","        [[-0.0431],\n","         [-0.0118],\n","         [-0.0667],\n","         ...,\n","         [ 0.0510],\n","         [ 0.0039],\n","         [-0.0980]],\n","\n","        [[-0.0431],\n","         [-0.0039],\n","         [ 0.0431],\n","         ...,\n","         [ 0.0431],\n","         [-0.0118],\n","         [-0.1137]],\n","\n","        [[-0.0353],\n","         [-0.0118],\n","         [ 0.1137],\n","         ...,\n","         [ 0.0353],\n","         [-0.0196],\n","         [-0.1137]]])\n","torch.Size([256, 256, 1])\n","\n","tensor([[ 0.2314],\n","        [ 0.2392],\n","        [ 0.2314],\n","        ...,\n","        [ 0.0353],\n","        [-0.0196],\n","        [-0.1137]])\n","torch.Size([65536, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Peq-S3C-GukN"},"source":["<a id='section_1'></a>\n","## *1.* Fitting an image\n","\n","First, let's simply fit that image!\n","\n","We seek to parameterize a greyscale image $f(x)$ with pixel coordinates $x$ with a SIREN $\\Phi(x)$.\n","\n","That is we seek the function $\\Phi$ such that:\n","$\\mathcal{L}=\\int_{\\Omega} \\lVert \\Phi(\\mathbf{x}) - f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x}$\n"," is minimized, in which $\\Omega$ is the domain of the image. \n"," \n","We write a little datast that does nothing except calculating per-pixel coordinates:"]},{"cell_type":"code","metadata":{"id":"_hr44pVJGukN","executionInfo":{"status":"ok","timestamp":1612134803035,"user_tz":-60,"elapsed":2595,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["class ImageFitting(Dataset):\n","    def __init__(self, sidelength):\n","        super().__init__()\n","\n","        #get the cameraman tensor with dimension sidelength\n","        #image tensor of dimension (1, sidelength, sidelength)\n","        img = get_cameraman_tensor(sidelength)\n","\n","        #tensor.permute(*dims):\n","        #Returns a view of the original tensor with its dimensions permuted\n","\n","        #I obtain an image tensor of dimension (sidelength, sidelength, 1)\n","\n","        #tensor.view(*shape)\n","        #Returns a new tensor with the same data as the self tensor but of a\n","        #different shape\n","        #dim = -1 -> calculate the dimensions automatically\n","\n","        #to obtain an image tensor of dimension (sidelength x sidelength, 1)\n","        \n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        #I obtain an image tensor of dimension (sidelength x sidelength, 1)\n","        #this represents the y (output) value for each pixel\n","\n","        #get mgrid of the same dimension of the image (sidelength)\n","        self.coords = get_mgrid(sidelength, 2)\n","        #I obtain a grid tensor of dimension (sidelength x sidelength, 2)\n","        #this represents the (x1, x2) (input) pair for each pixel\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):    \n","        if idx > 0: raise IndexError\n","            \n","        return self.coords, self.pixels"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5tlZdoUnGukN"},"source":["Let's instantiate the dataset and our Siren. As pixel coordinates are 2D, the siren has 2 input features, and since the image is grayscale, it has one output channel."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vxiLBwoGukN","executionInfo":{"status":"ok","timestamp":1612134806955,"user_tz":-60,"elapsed":6512,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"e4e6be91-3663-41e4-cf62-00927d161d2a"},"source":["cameraman = ImageFitting(256)\n","\n","#instantiate data loader with a single batch (we have only one image)\n","dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n","\n","#instantiate siren net with number of input features = 2 ((x1,x2) pairs),\n","#number of output features = 1 (y value), hidden features, hidden layers\n","#and if to have the last layer as a linear layer or not\n","img_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n","                  hidden_layers=2, outermost_linear=True)\n","\n","img_siren.cuda()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Siren(\n","  (net): Sequential(\n","    (0): SineLayer(\n","      (linear): Linear(in_features=2, out_features=256, bias=True)\n","    )\n","    (1): SineLayer(\n","      (linear): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (2): SineLayer(\n","      (linear): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (3): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"5L1JNw8OGukN"},"source":["We now fit Siren in a simple training loop. Within only hundreds of iterations, the image and its gradients are approximated well."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":111},"id":"DD_RdhMfGukN","executionInfo":{"status":"ok","timestamp":1612134806956,"user_tz":-60,"elapsed":6510,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"d9a51c5a-16ec-48fe-c844-48494c8ecdbc"},"source":["total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10 #steps at which print image and summary\n","\n","#define optimizer\n","optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n","\n","#model_input is the grid (of (x1,x2) pairs)\n","#ground_truth is the image (y values)\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","for step in range(total_steps):\n","\n","    #model_output is the output of the single forward pass, it is an output image\n","    #tensor of dimension (sidelength x sidelength, 1);\n","    #this represents the y^ (output) value for each pixel\n","\n","    #coords is a copy of the model_input pairs\n","    model_output, coords = img_siren(model_input) #forward pass \n","\n","    #model_output and ground_truth (original image) have the same dimensions\n","    loss = ((model_output - ground_truth)**2).mean()  #calculate loss (MSE)\n","    the_psnr = psnr(ground_truth, model_output)\n","    \n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total MSR loss %0.6f\" % (step, loss))\n","        img_grad = gradient(model_output, coords) #calculate output image gradient\n","        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\n","\n","        fig, axes = plt.subplots(1,4, figsize=(18,6))\n","        axes[0].set_title(\"PSNR: %0.4f \" % the_psnr)\n","        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[1].set_title(\"Gradient\")\n","        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[2].set_title(\"Laplacian\")\n","        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        axes[3].set_title(\"Ground Truth\")\n","        axes[3].imshow(ground_truth.cpu().view(256,256).detach().numpy())\n","\n","        plt.show()\n","\n","    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\n","    loss.backward() ##apply gradients\n","    optim.step()  #make optimizer step"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntotal_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\\nsteps_til_summary = 10 #steps at which print image and summary\\n\\n#define optimizer\\noptim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\\n\\n#model_input is the grid (of (x1,x2) pairs)\\n#ground_truth is the image (y values)\\nmodel_input, ground_truth = next(iter(dataloader))\\nmodel_input, ground_truth = model_input.cuda(), ground_truth.cuda()\\n\\nfor step in range(total_steps):\\n\\n    #model_output is the output of the single forward pass, it is an output image\\n    #tensor of dimension (sidelength x sidelength, 1);\\n    #this represents the y^ (output) value for each pixel\\n\\n    #coords is a copy of the model_input pairs\\n    model_output, coords = img_siren(model_input) #forward pass \\n\\n    #model_output and ground_truth (original image) have the same dimensions\\n    loss = ((model_output - ground_truth)**2).mean()  #calculate loss (MSE)\\n    the_psnr = psnr(ground_truth, model_output)\\n    \\n    if not step % steps_til_summary:\\n        print(\"Step %d, Total MSR loss %0.6f\" % (step, loss))\\n        img_grad = gradient(model_output, coords) #calculate output image gradient\\n        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\\n\\n        fig, axes = plt.subplots(1,4, figsize=(18,6))\\n        axes[0].set_title(\"PSNR: %0.4f \" % the_psnr)\\n        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\\n        axes[1].set_title(\"Gradient\")\\n        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\\n        axes[2].set_title(\"Laplacian\")\\n        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\\n        axes[3].set_title(\"Ground Truth\")\\n        axes[3].imshow(ground_truth.cpu().view(256,256).detach().numpy())\\n\\n        plt.show()\\n\\n    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\\n    loss.backward() ##apply gradients\\n    optim.step()  #make optimizer step\\n'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"exVGBGNsGukN"},"source":["<a id='section_3'></a>\n","## *2.* Solving Poisson's equation\n","\n","Now, let's make it a bit harder. Let's say we want to reconstruct an image but we only have access to its gradients!\n","\n","That is, we now seek the function $\\Phi$ such that:\n","$\\mathcal{L}=\\int_{\\Omega} \\lVert \\nabla\\Phi(\\mathbf{x}) - \\nabla f(\\mathbf{x}) \\rVert\\mathrm{d}\\mathbf{x}$\n"," is minimized, in which $\\Omega$ is the domain of the image. "]},{"cell_type":"code","metadata":{"id":"KwTh6TBFGukN","executionInfo":{"status":"ok","timestamp":1612134806956,"user_tz":-60,"elapsed":6506,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["import scipy.ndimage\n","    \n","class PoissonEqn(Dataset):\n","    def __init__(self, sidelength):\n","        super().__init__()\n","\n","        #get the cameraman tensor with dimension sidelength\n","        #image tensor of dimension (1, sidelength, sidelength)\n","        img = get_cameraman_tensor(sidelength)\n","        \n","        # Compute gradient and laplacian  \n","\n","        #scipy.ndimage.sobel(...)\n","        #Calculate a Sobel filter (axis is the axis of input along which to calculate)\n","        #returns a ndarray of dimension (1, sidelength, sidelength) in this case\n","\n","        #torch.squeeze(0)\n","        #Remove single-dimensional entries from the shape of a (along the 0 axis)\n","        #returns a ndarray of dimension (sidelength, sidelength) in this case\n","\n","        #ndarray [...,None]\n","        #changes the ndarray shape\n","        #returns a ndarray of dimension (sidelength, sidelength, 1) in this case\n","\n","        grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n","        grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n","\n","        #torch.from_numpy\n","        #Creates a Tensor from a numpy.ndarray\n","\n","        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n","                \n","        #torch.stack(...,dim=-1):\n","        #Concatenates a sequence of tensors along a new dimension\n","        #dim = -1 -> calculate the dimensions automatically\n","\n","        #tensor.view(*shape)\n","        #Returns a new tensor with the same data as the self tensor but of a\n","        #different shape\n","        #dim = -1 -> calculate the dimensions automatically\n","\n","        #to obtain a grad tensor of dimension (sidelength x sidelength, 2)\n","\n","        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n","\n","        #scipy.ndimage.laplace\n","        #N-D Laplace filter based on approximate second derivatives\n","        #returns a ndarray of dimension (1, sidelength, sidelength) in this case\n","\n","        #torch.squeeze(0)\n","        #Remove single-dimensional entries from the shape of a (along the 0 axis)\n","        #returns a ndarray of dimension (sidelength, sidelength) in this case\n","\n","        #ndarray [...,None]\n","        #changes the ndarray shape\n","        #returns a ndarray of dimension (sidelength, sidelength, 1) in this case\n","\n","        self.laplace = scipy.ndimage.laplace(img.numpy()).squeeze(0)[..., None]\n","\n","        #torch.from_numpy\n","        #Creates a Tensor from a numpy.ndarray\n","\n","        self.laplace = torch.from_numpy(self.laplace)\n","\n","        #tensor.permute(*dims):\n","        #Returns a view of the original tensor with its dimensions permuted\n","\n","        #I obtain an image tensor of dimension (sidelength, sidelength, 1)\n","\n","        #tensor.view(*shape)\n","        #Returns a new tensor with the same data as the self tensor but of a\n","        #different shape\n","        #dim = -1 -> calculate the dimensions automatically\n","\n","        #to obtain an image tensor of dimension (sidelength x sidelength, 1)\n","        \n","        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n","        #I obtain an image tensor of dimension (sidelength x sidelength, 1)\n","        #this represents the y (output) value for each pixel\n","\n","        #get mgrid of the same dimension of the image (sidelength)\n","        self.coords = get_mgrid(sidelength, 2)\n","        #I obtain a grid tensor of dimension (sidelength x sidelength, 2)\n","        #this represents the (x1, x2) (input) pair for each pixel\n","\n","    def __len__(self):\n","        return 1\n","\n","    def __getitem__(self, idx):\n","        return self.coords, {'pixels':self.pixels, 'grads':self.grads, 'laplace':self.laplace}"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqIgLfWcQapj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612134806957,"user_tz":-60,"elapsed":6505,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"603edf54-7ac0-4aa1-aba8-90fcf1570151"},"source":["import scipy.ndimage\n","\n","img = get_cameraman_tensor(256)\n","grads_x_1 = scipy.ndimage.sobel(img.numpy(), axis=1)\n","\n","print(grads_x_1)\n","print()\n","\n","grads_x_2 = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)\n","\n","print(grads_x_2)\n","print()\n","\n","grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n","grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n","\n","print(grads_x)\n","print(grads_y)\n","\n","grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n","\n","print(torch.stack((grads_x, grads_y), dim=-1))\n","grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n","print(grads)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[[-0.06274509 -0.12549019 -0.03137255 ...  0.25098038  0.18823528\n","    0.06274509]\n","  [-0.03137255 -0.09411764 -0.12549019 ...  0.15686274  0.18823528\n","    0.15686274]\n","  [ 0.         -0.03137255 -0.09411764 ... -0.03137255  0.03137255\n","    0.09411764]\n","  ...\n","  [ 0.8784313   1.3490198   2.1333337  ...  1.3490202   0.40784335\n","   -0.18823528]\n","  [ 0.09411764  0.75294137  2.7294123  ... -0.65882397 -0.31372595\n","   -0.28235316]\n","  [ 0.06274509  0.25098038  1.0039217  ... -0.3764708  -0.09411764\n","   -0.03137255]]]\n","\n","[[-0.06274509 -0.12549019 -0.03137255 ...  0.25098038  0.18823528\n","   0.06274509]\n"," [-0.03137255 -0.09411764 -0.12549019 ...  0.15686274  0.18823528\n","   0.15686274]\n"," [ 0.         -0.03137255 -0.09411764 ... -0.03137255  0.03137255\n","   0.09411764]\n"," ...\n"," [ 0.8784313   1.3490198   2.1333337  ...  1.3490202   0.40784335\n","  -0.18823528]\n"," [ 0.09411764  0.75294137  2.7294123  ... -0.65882397 -0.31372595\n","  -0.28235316]\n"," [ 0.06274509  0.25098038  1.0039217  ... -0.3764708  -0.09411764\n","  -0.03137255]]\n","\n","[[[-0.06274509]\n","  [-0.12549019]\n","  [-0.03137255]\n","  ...\n","  [ 0.25098038]\n","  [ 0.18823528]\n","  [ 0.06274509]]\n","\n"," [[-0.03137255]\n","  [-0.09411764]\n","  [-0.12549019]\n","  ...\n","  [ 0.15686274]\n","  [ 0.18823528]\n","  [ 0.15686274]]\n","\n"," [[ 0.        ]\n","  [-0.03137255]\n","  [-0.09411764]\n","  ...\n","  [-0.03137255]\n","  [ 0.03137255]\n","  [ 0.09411764]]\n","\n"," ...\n","\n"," [[ 0.8784313 ]\n","  [ 1.3490198 ]\n","  [ 2.1333337 ]\n","  ...\n","  [ 1.3490202 ]\n","  [ 0.40784335]\n","  [-0.18823528]]\n","\n"," [[ 0.09411764]\n","  [ 0.75294137]\n","  [ 2.7294123 ]\n","  ...\n","  [-0.65882397]\n","  [-0.31372595]\n","  [-0.28235316]]\n","\n"," [[ 0.06274509]\n","  [ 0.25098038]\n","  [ 1.0039217 ]\n","  ...\n","  [-0.3764708 ]\n","  [-0.09411764]\n","  [-0.03137255]]]\n","[[[ 0.06274509]\n","  [ 0.        ]\n","  [-0.15686274]\n","  ...\n","  [-0.12549019]\n","  [ 0.06274509]\n","  [ 0.06274509]]\n","\n"," [[-0.03137255]\n","  [-0.03137255]\n","  [-0.06274509]\n","  ...\n","  [-0.09411764]\n","  [ 0.        ]\n","  [-0.03137255]]\n","\n"," [[-0.06274509]\n","  [-0.09411764]\n","  [-0.09411764]\n","  ...\n","  [-0.03137255]\n","  [ 0.03137255]\n","  [-0.03137255]]\n","\n"," ...\n","\n"," [[ 0.43921566]\n","  [ 0.15686297]\n","  [-2.007843  ]\n","  ...\n","  [-0.15686297]\n","  [-2.0392163 ]\n","  [-1.4431376 ]]\n","\n"," [[ 0.5333333 ]\n","  [ 1.1921575 ]\n","  [-0.2823527 ]\n","  ...\n","  [-0.3450985 ]\n","  [-2.4470596 ]\n","  [-1.6000001 ]]\n","\n"," [[ 0.43921566]\n","  [ 2.1333342 ]\n","  [ 1.505883  ]\n","  ...\n","  [ 0.25098014]\n","  [-2.415687  ]\n","  [-1.5372548 ]]]\n","tensor([[[[-0.0627,  0.0627]],\n","\n","         [[-0.1255,  0.0000]],\n","\n","         [[-0.0314, -0.1569]],\n","\n","         ...,\n","\n","         [[ 0.2510, -0.1255]],\n","\n","         [[ 0.1882,  0.0627]],\n","\n","         [[ 0.0627,  0.0627]]],\n","\n","\n","        [[[-0.0314, -0.0314]],\n","\n","         [[-0.0941, -0.0314]],\n","\n","         [[-0.1255, -0.0627]],\n","\n","         ...,\n","\n","         [[ 0.1569, -0.0941]],\n","\n","         [[ 0.1882,  0.0000]],\n","\n","         [[ 0.1569, -0.0314]]],\n","\n","\n","        [[[ 0.0000, -0.0627]],\n","\n","         [[-0.0314, -0.0941]],\n","\n","         [[-0.0941, -0.0941]],\n","\n","         ...,\n","\n","         [[-0.0314, -0.0314]],\n","\n","         [[ 0.0314,  0.0314]],\n","\n","         [[ 0.0941, -0.0314]]],\n","\n","\n","        ...,\n","\n","\n","        [[[ 0.8784,  0.4392]],\n","\n","         [[ 1.3490,  0.1569]],\n","\n","         [[ 2.1333, -2.0078]],\n","\n","         ...,\n","\n","         [[ 1.3490, -0.1569]],\n","\n","         [[ 0.4078, -2.0392]],\n","\n","         [[-0.1882, -1.4431]]],\n","\n","\n","        [[[ 0.0941,  0.5333]],\n","\n","         [[ 0.7529,  1.1922]],\n","\n","         [[ 2.7294, -0.2824]],\n","\n","         ...,\n","\n","         [[-0.6588, -0.3451]],\n","\n","         [[-0.3137, -2.4471]],\n","\n","         [[-0.2824, -1.6000]]],\n","\n","\n","        [[[ 0.0627,  0.4392]],\n","\n","         [[ 0.2510,  2.1333]],\n","\n","         [[ 1.0039,  1.5059]],\n","\n","         ...,\n","\n","         [[-0.3765,  0.2510]],\n","\n","         [[-0.0941, -2.4157]],\n","\n","         [[-0.0314, -1.5373]]]])\n","tensor([[-0.0627,  0.0627],\n","        [-0.1255,  0.0000],\n","        [-0.0314, -0.1569],\n","        ...,\n","        [-0.3765,  0.2510],\n","        [-0.0941, -2.4157],\n","        [-0.0314, -1.5373]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KXnTf64EGukN"},"source":["#### Instantiate SIREN model"]},{"cell_type":"code","metadata":{"id":"-FknDYYlGukN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612134806957,"user_tz":-60,"elapsed":6502,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"4390a1d7-6d71-461d-9433-b34934908a23"},"source":["cameraman_poisson = PoissonEqn(256)\n","\n","#instantiate data loader with a single batch (we have only one image)\n","dataloader = DataLoader(cameraman_poisson, batch_size=1, pin_memory=True, num_workers=0)\n","\n","#instantiate siren net with number of input features = 2 ((x1,x2) pairs),\n","#number of output features = 1 (y value), hidden features, hidden layers\n","#and if to have the last layer as a linear layer or not\n","poisson_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n","                      hidden_layers=3, outermost_linear=True)\n","poisson_siren.cuda()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Siren(\n","  (net): Sequential(\n","    (0): SineLayer(\n","      (linear): Linear(in_features=2, out_features=256, bias=True)\n","    )\n","    (1): SineLayer(\n","      (linear): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (2): SineLayer(\n","      (linear): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (3): SineLayer(\n","      (linear): Linear(in_features=256, out_features=256, bias=True)\n","    )\n","    (4): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"HkHJhbonGukN"},"source":["#### Define the loss function"]},{"cell_type":"code","metadata":{"id":"M3bK6v14GukN","executionInfo":{"status":"ok","timestamp":1612134806957,"user_tz":-60,"elapsed":6499,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["def gradients_mse(model_output, coords, gt_gradients):\n","    # compute gradients on the model\n","\n","    #calculate the gradient from the output image of the model\n","    gradients = gradient(model_output, coords)\n","\n","    # compare them with the ground-truth gradients (mean squared error)\n","    gradients_loss = torch.mean((gradients - gt_gradients).pow(2).sum(-1))\n","    return gradients_loss"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6cIH_MDXGukN"},"source":["#### Train the model (from gradient)"]},{"cell_type":"code","metadata":{"id":"8navZ1QuGukN","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1612134806957,"user_tz":-60,"elapsed":6497,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"d7c31f09-11dc-42e3-9c49-2115a94d24c5"},"source":["total_steps = 500  # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10  #steps at which print image and summary\n","\n","#define optimizer\n","optim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\n","\n","#model_input is the grid (of (x1,x2) pairs)\n","#ground truth is the image (y values)\n","model_input, gt = next(iter(dataloader))\n","\n","#ground truth is composed of 3 terms (pixels, grads, laplace), move them to cuda\n","gt = {key: value.cuda() for key, value in gt.items()}\n","\n","model_input = model_input.cuda()\n","\n","for step in range(total_steps):\n","    start_time = time.time()\n","\n","    #model_output is the output of the single forward pass, it is an output image\n","    #tensor of dimension (sidelength x sidelength, 1);\n","    #this represents the y^ (output) value for each pixel\n","\n","    #coords is a copy of the model_input pairs  \n","    model_output, coords = poisson_siren(model_input) #forward pass \n","\n","    #model_output and ground_truth (original image) have the same dimensions\n","\n","    #calculate MSE\n","    train_loss = gradients_mse(model_output, coords, gt['grads'])\n","    the_psnr = psnr(gt['pixels'], model_output)\n","\n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f, iteration time %0.6f\" % (step, train_loss, time.time() - start_time))\n","\n","        img_grad = gradient(model_output, coords) #calculate output image gradient\n","        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\n","\n","        fig, axes = plt.subplots(2,3, figsize=(18,10))\n","        axes[0, 0].set_title(\"PSNR: %0.4f \" % the_psnr)\n","        axes[0, 0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[0, 1].set_title(\"Our Gradient\")\n","        axes[0, 1].imshow(img_grad.cpu().norm(dim=-1).view(256,256).detach().numpy())\n","        axes[0, 2].set_title(\"Our Laplacian\")\n","        axes[0, 2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        axes[1, 0].set_title(\"Ground Truth\")\n","        axes[1, 0].imshow(gt['pixels'].cpu().view(256,256).detach().numpy())\n","        axes[1, 1].set_title(\"Ground Truth Gradient\")\n","        axes[1, 1].imshow(gt['grads'].norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[1, 2].set_title(\"Ground Truth Laplacian\")\n","        axes[1, 2].imshow(gt['laplace'].cpu().view(256,256).detach().numpy())\n","        plt.show()\n","        \n","    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\n","    train_loss.backward() #apply gradients\n","    optim.step()  #make optimizer step"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntotal_steps = 500  # Since the whole image is our dataset, this just means 500 gradient descent steps.\\nsteps_til_summary = 10  #steps at which print image and summary\\n\\n#define optimizer\\noptim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\\n\\n#model_input is the grid (of (x1,x2) pairs)\\n#ground truth is the image (y values)\\nmodel_input, gt = next(iter(dataloader))\\n\\n#ground truth is composed of 3 terms (pixels, grads, laplace), move them to cuda\\ngt = {key: value.cuda() for key, value in gt.items()}\\n\\nmodel_input = model_input.cuda()\\n\\nfor step in range(total_steps):\\n    start_time = time.time()\\n\\n    #model_output is the output of the single forward pass, it is an output image\\n    #tensor of dimension (sidelength x sidelength, 1);\\n    #this represents the y^ (output) value for each pixel\\n\\n    #coords is a copy of the model_input pairs  \\n    model_output, coords = poisson_siren(model_input) #forward pass \\n\\n    #model_output and ground_truth (original image) have the same dimensions\\n\\n    #calculate MSE\\n    train_loss = gradients_mse(model_output, coords, gt[\\'grads\\'])\\n    the_psnr = psnr(gt[\\'pixels\\'], model_output)\\n\\n    if not step % steps_til_summary:\\n        print(\"Step %d, Total loss %0.6f, iteration time %0.6f\" % (step, train_loss, time.time() - start_time))\\n\\n        img_grad = gradient(model_output, coords) #calculate output image gradient\\n        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\\n\\n        fig, axes = plt.subplots(2,3, figsize=(18,10))\\n        axes[0, 0].set_title(\"PSNR: %0.4f \" % the_psnr)\\n        axes[0, 0].imshow(model_output.cpu().view(256,256).detach().numpy())\\n        axes[0, 1].set_title(\"Our Gradient\")\\n        axes[0, 1].imshow(img_grad.cpu().norm(dim=-1).view(256,256).detach().numpy())\\n        axes[0, 2].set_title(\"Our Laplacian\")\\n        axes[0, 2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\\n        axes[1, 0].set_title(\"Ground Truth\")\\n        axes[1, 0].imshow(gt[\\'pixels\\'].cpu().view(256,256).detach().numpy())\\n        axes[1, 1].set_title(\"Ground Truth Gradient\")\\n        axes[1, 1].imshow(gt[\\'grads\\'].norm(dim=-1).cpu().view(256,256).detach().numpy())\\n        axes[1, 2].set_title(\"Ground Truth Laplacian\")\\n        axes[1, 2].imshow(gt[\\'laplace\\'].cpu().view(256,256).detach().numpy())\\n        plt.show()\\n        \\n    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\\n    train_loss.backward() #apply gradients\\n    optim.step()  #make optimizer step\\n'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"nP9rpgesgR_X"},"source":["#### Train the model (from laplacian)\r\n","\r\n","> Blocco con rientro\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qq5N_NGNPe3QzgERotYHZjrXuWdlwuRr"},"id":"hmu2X-uZgDsy","executionInfo":{"status":"ok","timestamp":1612142126624,"user_tz":-60,"elapsed":7326160,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"a89b73bb-cb1c-4150-d5d4-e924d4cf6a45"},"source":["poisson_siren = Siren(in_features=2, out_features=1, hidden_features=256, \r\n","                      hidden_layers=3, outermost_linear=True)\r\n","poisson_siren.cuda()\r\n","\r\n","def laplace_mse(model_output, coords, gt_laplace):\r\n","    # compute gradients on the model\r\n","\r\n","    #calculate the gradient from the output image of the model\r\n","    laplacian = laplace(model_output, coords)\r\n","\r\n","    # compare them with the ground-truth gradients (mean squared error)\r\n","    laplace_loss = torch.mean((laplacian.view(256,256) - gt_laplace.view(256,256)).pow(2).sum(-1))\r\n","    return laplace_loss\r\n","\r\n","total_steps = 500  # Since the whole image is our dataset, this just means 500 gradient descent steps.\r\n","steps_til_summary = 10  #steps at which print image and summary\r\n","\r\n","#define optimizer\r\n","optim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\r\n","\r\n","#model_input is the grid (of (x1,x2) pairs)\r\n","#ground truth is the image (y values)\r\n","model_input, gt = next(iter(dataloader))\r\n","\r\n","#ground truth is composed of 3 terms (pixels, grads, laplace), move them to cuda\r\n","gt = {key: value.cuda() for key, value in gt.items()}\r\n","\r\n","model_input = model_input.cuda()\r\n","\r\n","for step in range(total_steps):\r\n","    start_time = time.time()\r\n","\r\n","    #model_output is the output of the single forward pass, it is an output image\r\n","    #tensor of dimension (sidelength x sidelength, 1);\r\n","    #this represents the y^ (output) value for each pixel\r\n","\r\n","    #coords is a copy of the model_input pairs  \r\n","    model_output, coords = poisson_siren(model_input) #forward pass \r\n","\r\n","    #model_output and ground_truth (original image) have the same dimensions\r\n","\r\n","    #calculate MSE\r\n","    train_loss = laplace_mse(model_output, coords, gt['laplace'])\r\n","    the_psnr = psnr(gt['pixels'], model_output)\r\n","\r\n","    if not step % steps_til_summary:\r\n","        print(\"Step %d, Total loss %0.6f, iteration time %0.6f\" % (step, train_loss, time.time() - start_time))\r\n","\r\n","        img_grad = gradient(model_output, coords) #calculate output image gradient\r\n","        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\r\n","\r\n","        fig, axes = plt.subplots(2,3, figsize=(18,10))\r\n","        axes[0, 0].set_title(\"PSNR: %0.4f \" % the_psnr)\r\n","        axes[0, 0].imshow(model_output.cpu().view(256,256).detach().numpy())\r\n","        axes[0, 1].set_title(\"Our Gradient\")\r\n","        axes[0, 1].imshow(img_grad.cpu().norm(dim=-1).view(256,256).detach().numpy())\r\n","        axes[0, 2].set_title(\"Our Laplacian\")\r\n","        axes[0, 2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\r\n","        axes[1, 0].set_title(\"Ground Truth\")\r\n","        axes[1, 0].imshow(gt['pixels'].cpu().view(256,256).detach().numpy())\r\n","        axes[1, 1].set_title(\"Ground Truth Gradient\")\r\n","        axes[1, 1].imshow(gt['grads'].norm(dim=-1).cpu().view(256,256).detach().numpy())\r\n","        axes[1, 2].set_title(\"Ground Truth Laplacian\")\r\n","        axes[1, 2].imshow(gt['laplace'].cpu().view(256,256).detach().numpy())\r\n","        plt.show()\r\n","        \r\n","    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\r\n","    train_loss.backward() #apply gradients\r\n","    optim.step()  #make optimizer step"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"b_9NE8sTcdid"},"source":["<a id='section_4'></a>\n","## *3.* Siren vs Relu\n","\n","I will now compare Siren with a fully connected net using ReLU activation function"]},{"cell_type":"code","metadata":{"id":"vv9Wx7vddVl8","executionInfo":{"status":"ok","timestamp":1612142126645,"user_tz":-60,"elapsed":7326177,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}}},"source":["class ReluNet(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features):\n","        super().__init__()\n","        \n","        self.net = []   #net\n","\n","        #append the first fully connected layer\n","        self.net.append(nn.Linear(in_features, hidden_features))\n","        self.net.append(nn.ReLU())\n","\n","        #append all the other fully connected layers\n","        for i in range(hidden_layers):\n","            self.net.append(nn.Linear(hidden_features, hidden_features))\n","            self.net.append(nn.ReLU())\n","\n","        #append the final fully connected layer\n","        self.net.append(nn.Linear(hidden_features, out_features))\n","\n","        \n","        \n","        #nn.Sequential(*self.net):\n","        #A sequential container. Modules will be added to it in the order they\n","        #are passed in the constructor.\n","\n","        self.net = nn.Sequential(*self.net)\n","    \n","    def forward(self, coords):  #forward pass\n","        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n","        output = self.net(coords) #apply coords on net\n","        return output, coords        \n","\n","    def forward_with_activations(self, coords, retain_grad=False):  #forward pass with activations\n","        '''Returns not only model output, but also intermediate activations.\n","        Only used for visualizing activations later!'''\n","        activations = OrderedDict()\n","\n","        activation_count = 0\n","        x = coords.clone().detach().requires_grad_(True)  # allows to take derivative w.r.t. input\n","        activations['input'] = x\n","        for i, layer in enumerate(self.net):  #for all layers of the net\n","            if isinstance(layer, SineLayer):  #if it is a sine layer\n","                x, intermed = layer.forward_with_intermediate(x)\n","                \n","                #retain_grad():\n","                #Enables .grad attribute for non-leaf Tensors.\n","\n","                if retain_grad:\n","                    x.retain_grad()\n","                    intermed.retain_grad()\n","                    \n","                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n","                activation_count += 1\n","            else: \n","                x = layer(x)\n","                \n","                if retain_grad:\n","                    x.retain_grad()\n","                    \n","            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n","            activation_count += 1\n","\n","        return activations"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbkY60XkfAnD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612142126647,"user_tz":-60,"elapsed":7326178,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"43270533-4a41-41f0-e2d0-c406157c204f"},"source":["#free some memory\n","try:\n","    img_siren\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del img_siren\n","\n","try:\n","    img_relu\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del img_relu\n","\n","try:\n","    optim\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del optim\n","\n","try:\n","    model_input\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del model_input\n","\n","try:\n","    model_output\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del model_output\n","\n","try:\n","    img_grad\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del img_grad\n","\n","try:\n","    img_laplacian\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del img_laplacian\n","\n","try:\n","    new_model_input\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del new_model_input\n","\n","try:\n","    new_model_output\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del new_model_output\n","\n","try:\n","    new_ground_truth\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del new_ground_truth\n","\n","try:\n","    new_coords\n","except NameError:\n","    print(\"first time\")\n","else:\n","    del new_coords"],"execution_count":18,"outputs":[{"output_type":"stream","text":["first time\n","first time\n","first time\n","first time\n","first time\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bjRKIIHxdmrn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612142126647,"user_tz":-60,"elapsed":7326175,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"34c00596-21a3-4eb0-f470-d329c973aef7"},"source":["cameraman = ImageFitting(256)\n","\n","#instantiate data loader with a single batch (we have only one image)\n","dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)\n","\n","#instantiate siren net with number of input features = 2 ((x1,x2) pairs),\n","#number of output features = 1 (y value), hidden features, hidden layers\n","#and if to have the last layer as a linear layer or not\n","img_siren = Siren(in_features=2, out_features=1, hidden_features=256, \n","                  hidden_layers=2, outermost_linear=True)\n","\n","img_relu = ReluNet(in_features=2, out_features=1, hidden_features=256, \n","                  hidden_layers=2)\n","\n","img_siren.cuda(), img_relu.cuda()\n","\n","relu_total_params = sum(p.numel() for p in img_relu.parameters() if p.requires_grad)\n","print(\"Relu net parameters: %d\" % relu_total_params)\n","siren_total_params = sum(p.numel() for p in img_relu.parameters() if p.requires_grad)\n","print(\"Siren net parameters: %d\" % siren_total_params)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Relu net parameters: 132609\n","Siren net parameters: 132609\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RMH0zmrKeLG0"},"source":["### Siren"]},{"cell_type":"code","metadata":{"id":"SpsWGVqsd96q","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bJjjQF8kI9T8wJ9pB3J-ApaY3E_tRgVk"},"executionInfo":{"status":"ok","timestamp":1612142172019,"user_tz":-60,"elapsed":7371547,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"ea010bd2-3f0f-40c1-e932-d79799614ea0"},"source":["total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10 #steps at which print image and summary\n","\n","#define optimizer\n","optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n","\n","#model_input is the grid (of (x1,x2) pairs)\n","#ground_truth is the image (y values)\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","for step in range(total_steps):\n","\n","    #model_output is the output of the single forward pass, it is an output image\n","    #tensor of dimension (sidelength x sidelength, 1);\n","    #this represents the y^ (output) value for each pixel\n","\n","    #coords is a copy of the model_input pairs\n","    model_output, coords = img_siren(model_input) #forward pass \n","\n","    #model_output and ground_truth (original image) have the same dimensions\n","    loss = ((model_output - ground_truth)**2).mean()  #calculate loss (MSE)\n","    the_psnr = psnr(ground_truth, model_output)\n","    \n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","        img_grad = gradient(model_output, coords) #calculate output image gradient\n","        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\n","\n","        fig, axes = plt.subplots(1,4, figsize=(18,6))\n","        axes[0].set_title(\"PSNR: %0.4f\" % the_psnr)\n","        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[1].set_title(\"Gradient\")\n","        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[2].set_title(\"Laplacian\")\n","        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        axes[3].set_title(\"Ground Truth\")\n","        axes[3].imshow(ground_truth.cpu().view(256,256).detach().numpy())\n","\n","        plt.show()\n","\n","    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\n","    loss.backward() ##apply gradients\n","    optim.step()  #make optimizer step"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"uO71gt8seNjH"},"source":["### ReLU"]},{"cell_type":"code","metadata":{"id":"XivTARJ0eJ9z","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pA4HhQHBZIKjPKHF5ZJiKHT4RYk5ZHom"},"executionInfo":{"status":"ok","timestamp":1612142211997,"user_tz":-60,"elapsed":7411522,"user":{"displayName":"Thomas Madeo","photoUrl":"","userId":"15537587845074977383"}},"outputId":"e6b3f699-0e27-4c6a-8249-57691242b825"},"source":["total_steps = 500 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n","steps_til_summary = 10 #steps at which print image and summary\n","\n","#define optimizer\n","optim = torch.optim.Adam(lr=1e-4, params=img_relu.parameters())\n","\n","#model_input is the grid (of (x1,x2) pairs)\n","#ground_truth is the image (y values)\n","model_input, ground_truth = next(iter(dataloader))\n","model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n","\n","for step in range(total_steps):\n","\n","    #model_output is the output of the single forward pass, it is an output image\n","    #tensor of dimension (sidelength x sidelength, 1);\n","    #this represents the y^ (output) value for each pixel\n","\n","    #coords is a copy of the model_input pairs\n","    model_output, coords = img_relu(model_input) #forward pass \n","\n","    #model_output and ground_truth (original image) have the same dimensions\n","    loss = ((model_output - ground_truth)**2).mean()  #calculate loss (MSE)\n","    \n","    if not step % steps_til_summary:\n","        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n","        img_grad = gradient(model_output, coords) #calculate output image gradient\n","        img_laplacian = laplace(model_output, coords) #calculate output image laplacian\n","        the_psnr = psnr(ground_truth, model_output)\n","\n","        fig, axes = plt.subplots(1,4, figsize=(18,6))\n","        axes[0].set_title(\"PSNR: %0.4f\" % the_psnr)\n","        axes[0].imshow(model_output.cpu().view(256,256).detach().numpy())\n","        axes[1].set_title(\"Gradient\")\n","        axes[1].imshow(img_grad.norm(dim=-1).cpu().view(256,256).detach().numpy())\n","        axes[2].set_title(\"Laplacian\")\n","        axes[2].imshow(img_laplacian.cpu().view(256,256).detach().numpy())\n","        axes[3].set_title(\"Ground Truth\")\n","        axes[3].imshow(ground_truth.cpu().view(256,256).detach().numpy())\n","\n","        plt.show()\n","\n","    optim.zero_grad() #Sets the gradients of all optimized torch.Tensor to zero\n","    loss.backward() ##apply gradients\n","    optim.step()  #make optimizer step"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}