{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5_MLAI_hyper_SIREN_ISR_PRIOR_BRANCH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVwyj-wdHlSy",
        "outputId": "ee5c467a-468f-4e45-ae8b-cd62df7ae297"
      },
      "source": [
        "     from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyTeOirTH306",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f767c5df-e4a4-494b-c72c-503e98d834f4"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "import os\r\n",
        "\r\n",
        "if not os.path.isdir('./HypernetworkSiren'):\r\n",
        "  !git clone https://Trapper96:mlmlml.11@github.com/Trapper96/HypernetworkSiren.git\r\n",
        "  !bash -c 'mv ./HypernetworkSiren/* ./'\r\n",
        "  !bash -c 'rmdir ./HypernetworkSiren'\r\n",
        "\r\n",
        "\r\n",
        "from hypersiren import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'HypernetworkSiren'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 42135 (delta 75), reused 79 (delta 37), pack-reused 42017\u001b[K\n",
            "Receiving objects: 100% (42135/42135), 4.06 GiB | 50.35 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "Checking out files: 100% (1878/1878), done.\n",
            "rmdir: failed to remove './HypernetworkSiren': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "vITfgnN_ISmG",
        "outputId": "5618d379-9dfe-4fee-92a5-7b7a58559223"
      },
      "source": [
        "from hypersiren import *\r\n",
        "print_CUDA_memory_statistics()\r\n",
        "\r\n",
        "#put this to true if you want to resume a previous training\r\n",
        "restore = False\r\n",
        "data_augmentation = True\r\n",
        "\r\n",
        "## SUPER RESOLUTION PARAMETERS ##\r\n",
        "datasetTrainingPath = \"/content/images/DIV2K_train_HR\"\r\n",
        "datasetValidationPath = \"/content/images/DIV2K_valid_HR\"\r\n",
        "datasetTestPath = \"/content/images/Set14\"\r\n",
        "epochs = 1000\r\n",
        "steps_til_summary = 100\r\n",
        "max_num_images = 800\r\n",
        "max_val_images = 100\r\n",
        "max_test_images = 14\r\n",
        "batch_size = 25\r\n",
        "hidden_features = 128\r\n",
        "better_params = (30, 30, 2e-5, 0.1)\r\n",
        "lambda_latent = 1e-1\r\n",
        "lambda_weights = 1e2\r\n",
        "lambda_biases = 1e2\r\n",
        "width_LR = 64\r\n",
        "height_LR = 64\r\n",
        "factor = 4\r\n",
        "width_HR = width_LR * factor\r\n",
        "height_HR = height_LR * factor\r\n",
        "\r\n",
        "## WRITER AND CHECKPOINT PATH ##\r\n",
        "checkpoint_path = \"/content/drive/MyDrive/backup_training/SIREN_PRIOR_BRANCH_HyperMetaAlexNet_DA_ep\" + str(epochs) + \"_im\" + str(max_num_images) + \".chk\"\r\n",
        "writer_folder = \"/content/drive/MyDrive/backup_training/SIREN_PRIOR_BRANCH_HyperMetaAlexNet_DA_ep\" + str(epochs) + \"_im\" + str(max_num_images)\r\n",
        "\r\n",
        "## DATALOADER ##\r\n",
        "if data_augmentation:\r\n",
        "  # set dataloader with DA\r\n",
        "  training_dataloader = DataLoader(Hyper_ImageFitting_RGB_DA(datasetTrainingPath, width_LR, height_LR, factor, max = max_num_images, apply_random_transforms=True), batch_size=batch_size, pin_memory=True, num_workers=0, shuffle=True)\r\n",
        "  validation_dataloader = DataLoader(Hyper_ImageFitting_RGB_DA(datasetValidationPath, width_LR, height_LR, factor, max = max_val_images), batch_size=10, pin_memory=True, num_workers=0, shuffle=True)\r\n",
        "else:\r\n",
        "  # set dataloader without DA\r\n",
        "  training_dataloader = DataLoader(Hyper_ImageFitting_RGB(datasetTrainingPath, width_LR, height_LR, factor, max = max_num_images), batch_size=batch_size, pin_memory=True, num_workers=0, shuffle=True)\r\n",
        "  validation_dataloader = DataLoader(Hyper_ImageFitting_RGB(datasetValidationPath, width_LR, height_LR, factor, max = max_val_images), batch_size=10, pin_memory=True, num_workers=0, shuffle=True)\r\n",
        "\r\n",
        "## HYPERNETWORK ##\r\n",
        "# AlexNet: HyperBaseAlexNet.hyperBaseAlexNet\r\n",
        "# AlexNet with one FC for each SIREN layers: HyperBaseAlexNetFC.hyperBaseAlexNetFC\r\n",
        "# AlexNet with one FC for each weight and bias of SIREN layers: HyperMetaAlexNet.hyperMetaAlexNet\r\n",
        "hyper_siren = Hyp_Siren(in_features=2, out_features=3, hidden_features=hidden_features, hidden_layers=3, \r\n",
        "                           hypernetInit= HyperMetaAlexNet.hyperMetaAlexNet, first_omega_0=better_params[0], hidden_omega_0=better_params[1])\r\n",
        "\r\n",
        "hyper_siren.cuda()\r\n",
        "\r\n",
        "print_CUDA_memory_statistics()\r\n",
        "\r\n",
        "writer = SummaryWriter(writer_folder)\r\n",
        "\r\n",
        "## TRAINING ##\r\n",
        "prior_train(hyper_siren, training_dataloader, validation_dataloader, writer,\r\n",
        "            lr = better_params[2], gamma = better_params[3], width_HR = width_HR,\r\n",
        "            height_HR = height_HR, total_steps = epochs, \r\n",
        "            steps_til_summary = steps_til_summary, lambda_latent = lambda_latent,\r\n",
        "            lambda_weights = lambda_weights, lambda_biases = lambda_biases, \r\n",
        "            restore = restore, checkpoint_path = checkpoint_path)  \r\n",
        "\r\n",
        "writer.flush()\r\n",
        "\r\n",
        "print_CUDA_memory_statistics()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA-0 used memory [0 bytes / 17071734784 bytes (0.00%)]\n",
            "CUDA-0 used memory [474228736 bytes / 17071734784 bytes (2.78%)]\n",
            "CUDA-0 used memory [1903442944 bytes / 17071734784 bytes (11.15%)]\n",
            "Step 100, Total loss 0.030197, psnr_train: 15.839653, psnr_val: 15.867306\n",
            "Estimated time: 0:32:57 / 5:32:56\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1913045504 bytes / 17071734784 bytes (11.21%)]\n",
            "Step 200, Total loss 0.027188, psnr_train: 16.168380, psnr_val: 16.119585\n",
            "Estimated time: 1:5:33 / 5:29:26\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1914655744 bytes / 17071734784 bytes (11.22%)]\n",
            "Step 300, Total loss 0.025915, psnr_train: 16.309039, psnr_val: 16.339445\n",
            "Estimated time: 1:33:45 / 5:13:33\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1913613312 bytes / 17071734784 bytes (11.21%)]\n",
            "Step 400, Total loss 0.022584, psnr_train: 16.434710, psnr_val: 16.415325\n",
            "Estimated time: 2:5:50 / 5:15:23\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1914110976 bytes / 17071734784 bytes (11.21%)]\n",
            "Step 500, Total loss 0.026285, psnr_train: 16.603090, psnr_val: 16.521191\n",
            "Estimated time: 2:38:18 / 5:17:14\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1914110976 bytes / 17071734784 bytes (11.21%)]\n",
            "Step 600, Total loss 0.023247, psnr_train: 16.636062, psnr_val: 16.618342\n",
            "Estimated time: 3:9:50 / 5:16:55\n",
            "=> Saving model... Saved\n",
            "CUDA-0 used memory [1914110976 bytes / 17071734784 bytes (11.21%)]\n",
            "Step 700, Total loss 0.020957, psnr_train: 16.701066, psnr_val: 16.668074\n",
            "Estimated time: 3:42:45 / 5:18:40\n",
            "=> Saving model... Saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-82f90272c6ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0msteps_til_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_til_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_latent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mlambda_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_biases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_biases\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             restore = restore, checkpoint_path = checkpoint_path)  \n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hypersiren/training.py\u001b[0m in \u001b[0;36mprior_train\u001b[0;34m(net, dataloader, validationDataLoader, writer, lr, gamma, step, total_steps, steps_til_summary, width_HR, height_HR, lambda_latent, lambda_weights, lambda_biases, restore, checkpoint_path)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Sets the gradients of all optimized torch.Tensor to zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#apply gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#make optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZBHXVw97Hk9"
      },
      "source": [
        "import copy\r\n",
        "print_CUDA_memory_statistics()\r\n",
        "max_test_images = 14\r\n",
        "\r\n",
        "# load real image\r\n",
        "test_dataloader = DataLoader(TestImageFitting_RGB(datasetTestPath, width_LR, height_LR, factor, max = max_test_images), batch_size=1, pin_memory=True, num_workers=0, shuffle=False)\r\n",
        "\r\n",
        "estimator = Time_estimator(total_steps = max_test_images, steps_til_summary = 1)\r\n",
        "\r\n",
        "all_psnr_prior = []\r\n",
        "all_psnr_siren_prior = []\r\n",
        "all_psnr_siren_no_prior = []\r\n",
        "all_psnr_bicubic = []\r\n",
        "all_psnr_srresnet = []\r\n",
        "all_psnr_srgan = []\r\n",
        "\r\n",
        "iter = 0\r\n",
        "for input_grid_LR, input_grid_HR, ground_truth_HR, ground_truth_LR, original_ground_truth_LR, filename in test_dataloader:\r\n",
        "    iter += 1\r\n",
        "    input_grid_LR = input_grid_LR.cuda()\r\n",
        "    input_grid_HR = input_grid_HR.cuda()\r\n",
        "    ground_truth_HR = ground_truth_HR.cuda()\r\n",
        "    ground_truth_LR = ground_truth_LR.cuda()\r\n",
        "    original_ground_truth_LR = original_ground_truth_LR.cuda()\r\n",
        "\r\n",
        "    output_prior_image, _, weight_prior, bias_prior, _ = hyper_siren(original_ground_truth_LR, input_grid_HR)\r\n",
        "\r\n",
        "    #SIREN TRAIN WITH PRIOR --------------------------------------------------------\r\n",
        "    img_siren = Basic_Siren(in_features=2, out_features=3, hidden_features=hidden_features, hidden_layers=3, first_omega_0=30, \r\n",
        "                            hidden_omega_0=30, w = weight_prior, b = bias_prior)\r\n",
        "    img_siren.cuda()\r\n",
        "    train(img_siren, input_grid_LR, ground_truth_LR, name = os.path.basename(filename[0]) + \"/test_prior\", writer = writer, \r\n",
        "          lr = 0.0001, gamma = 0.1, width = width_LR, height = height_LR, total_steps = 1500)\r\n",
        "\r\n",
        "    siren_output_HR_prior, _ = img_siren(input_grid_HR)\r\n",
        "\r\n",
        "    #SIREN TRAIN WITHOUT PRIOR -----------------------------------------------------\r\n",
        "    img_siren = Basic_Siren(in_features=2, out_features=3, hidden_features=hidden_features, hidden_layers=3, first_omega_0=30, hidden_omega_0=30)\r\n",
        "    img_siren.cuda()\r\n",
        "    train(img_siren, input_grid_LR, ground_truth_LR, name = os.path.basename(filename[0]) + \"/test_no_prior\", writer = writer, \r\n",
        "          lr = 0.0001, gamma = 0.1, width = width_LR, height = height_LR, total_steps = 1500)\r\n",
        "\r\n",
        "    siren_output_HR_no_prior, _ = img_siren(input_grid_HR)\r\n",
        "    \r\n",
        "    print(\"[image {}/{} - {:.2%}]\".format(iter, max_test_images, iter/max_test_images))\r\n",
        "\r\n",
        "    # computing PSNR PRIOR\r\n",
        "    psnr_prior = psnr(target = ground_truth_HR, input = output_prior_image)\r\n",
        "    all_psnr_prior.append(psnr_prior)\r\n",
        "\r\n",
        "    # computing PSNR SIREN with prior\r\n",
        "    psnr_siren_prior = psnr(target = ground_truth_HR, input = siren_output_HR_prior)\r\n",
        "    all_psnr_siren_prior.append(psnr_siren_prior)\r\n",
        "\r\n",
        "    # computing PSNR SIREN with no prior\r\n",
        "    psnr_siren_no_prior = psnr(target = ground_truth_HR, input = siren_output_HR_no_prior)\r\n",
        "    all_psnr_siren_no_prior.append(psnr_siren_no_prior)\r\n",
        "    \r\n",
        "    # computing PSNR BICUBIC\r\n",
        "    print(get_bicubic_image(filename[0], width_LR, height_LR, width_HR, height_HR).permute(1, 2, 0).shape)\r\n",
        "    bicubic_output = get_bicubic_image(filename[0], width_LR, height_LR, width_HR, height_HR).permute(1, 2, 0).view(-1, 3)\r\n",
        "    bicubic_output = bicubic_output.cuda()\r\n",
        "\r\n",
        "    psnr_bicubic = psnr(target = ground_truth_HR, input = bicubic_output)\r\n",
        "    all_psnr_bicubic.append(psnr_bicubic)\r\n",
        "\r\n",
        "    # Save temp image for SRGAN and SRResNet\r\n",
        "    save_image(ground_truth_LR.squeeze().view(height_LR, width_LR, 3).permute(2, 0, 1), 'srgan/pred/tmp.png', nrow=4)\r\n",
        "\r\n",
        "    from srgan import eval\r\n",
        "\r\n",
        "    # computing PSNR SRGAN\r\n",
        "    srgan = getSRGAN('srgan/pred/tmp.png', height_HR, width_HR)\r\n",
        "    srgan = srgan.cuda()\r\n",
        "    psnr_srgan = psnr(target = ground_truth_HR, input = srgan)\r\n",
        "    all_psnr_srgan.append(psnr_srgan)\r\n",
        "\r\n",
        "    # computing PSNR SRResNet\r\n",
        "    srresnet = getSRRESNET('srgan/pred/tmp.png', height_HR, width_HR)\r\n",
        "    srresnet = srresnet.cuda()\r\n",
        "    psnr_srresnet = psnr(target = ground_truth_HR, input = srresnet)\r\n",
        "    all_psnr_srresnet.append(psnr_srresnet)\r\n",
        "\r\n",
        "\r\n",
        "    # PLOT result\r\n",
        "    fig, axes = plt.subplots(2,4, figsize=(18,10))\r\n",
        "    axes[0,0].set_title(\"LR IMAGE\")\r\n",
        "    axes[0,0].imshow(ground_truth_LR.cpu().view(height_LR, width_LR, 3).detach().numpy())\r\n",
        "    axes[0,1].set_title(\"PRIOR ISR, PSNR: %0.4f\" %psnr_prior)\r\n",
        "    axes[0,1].imshow(torch.clamp(output_prior_image.cpu(), min=0, max=1).view(height_HR, width_HR, 3).detach().numpy())\r\n",
        "    axes[0,2].set_title(\"SIREN PRIOR ISR, PSNR: %0.4f \" % psnr_siren_prior)\r\n",
        "    axes[0,2].imshow(torch.clamp(siren_output_HR_prior.cpu(), min=0, max=1).view(height_HR, width_HR, 3).detach().numpy())\r\n",
        "    axes[0,3].set_title(\"SIREN NO PRIOR ISR, PSNR: %0.4f \" % psnr_siren_no_prior)\r\n",
        "    axes[0,3].imshow(torch.clamp(siren_output_HR_no_prior.cpu(), min=0, max=1).view(height_HR, width_HR, 3).detach().numpy())\r\n",
        "\r\n",
        "    axes[1,0].set_title(\"BICUBIC ISR PSNR: %0.4f \" % psnr_bicubic)\r\n",
        "    axes[1,0].imshow(bicubic_output.cpu().view(height_HR, width_HR,3).detach().numpy())\r\n",
        "    axes[1,1].set_title(\"SRResNet PSNR: %0.4f \" % psnr_srresnet)\r\n",
        "    axes[1,1].imshow(srresnet.cpu().view(height_HR, width_HR,3).detach().numpy())\r\n",
        "    axes[1,2].set_title(\"SRGAN PSNR: %0.4f \" % psnr_srgan)\r\n",
        "    axes[1,2].imshow(srgan.cpu().view(height_HR, width_HR,3).detach().numpy())\r\n",
        "    axes[1,3].set_title(\"HR IMAGE\")\r\n",
        "    axes[1,3].imshow(ground_truth_HR.cpu().view(height_HR, width_HR,3).detach().numpy())\r\n",
        "\r\n",
        "    estimator.checkpoint(iter)\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    print_CUDA_memory_statistics()\r\n",
        "\r\n",
        "all_psnr_prior = np.array(all_psnr_prior)\r\n",
        "all_psnr_siren_prior = np.array(all_psnr_siren_prior)\r\n",
        "all_psnr_siren_no_prior = np.array(all_psnr_siren_no_prior)\r\n",
        "all_psnr_bicubic = np.array(all_psnr_bicubic)\r\n",
        "all_psnr_srresnet = np.array(all_psnr_srresnet)\r\n",
        "all_psnr_srgan = np.array(all_psnr_srgan)\r\n",
        "\r\n",
        "for i in range(max_test_images):\r\n",
        "    writer.add_scalars(\"psnr_test\",{\r\n",
        "        \"psnr_prior\": all_psnr_prior[i],\r\n",
        "        \"psnr_siren_prior\": all_psnr_siren_prior[i],\r\n",
        "        \"psnr_siren_no_prior\": all_psnr_siren_no_prior[i],\r\n",
        "        \"psnr_bicubic\": all_psnr_bicubic[i],\r\n",
        "        \"psnr_srresnet\": all_psnr_srresnet[i],\r\n",
        "        \"psnr_srgan\": all_psnr_srgan[i],\r\n",
        "    }, i)\r\n",
        "    writer.flush();\r\n",
        "\r\n",
        "avg_psnr_prior = all_psnr_prior.mean()\r\n",
        "avg_psnr_siren_prior = all_psnr_siren_prior.mean()\r\n",
        "avg_psnr_siren_no_prior = all_psnr_siren_no_prior.mean()\r\n",
        "avg_psnr_bicubic = all_psnr_bicubic.mean()\r\n",
        "avg_psnr_srresnet = all_psnr_srresnet.mean()\r\n",
        "avg_psnr_srgan = all_psnr_srgan.mean()\r\n",
        "\r\n",
        "print(\"Average psnr prior: {}\".format(avg_psnr_prior))\r\n",
        "print(\"Average psnr siren prior: {}\".format(avg_psnr_siren_prior))\r\n",
        "print(\"Average psnr siren no prior: {}\".format(avg_psnr_siren_no_prior))\r\n",
        "print(\"Average psnr bicubic: {}\".format(avg_psnr_bicubic))\r\n",
        "print(\"Average psnr srresnet: {}\".format(avg_psnr_srresnet))\r\n",
        "print(\"Average psnr srgan: {}\".format(avg_psnr_srgan))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NVKfrcgTt9W"
      },
      "source": [
        "#writer.close()\r\n",
        "%tensorboard --logdir {writer_folder}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}